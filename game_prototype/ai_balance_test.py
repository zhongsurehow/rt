#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIæ™ºèƒ½ç¨‹åº¦å’Œæ¸¸æˆå¹³è¡¡æ€§æµ‹è¯•
AI Intelligence and Game Balance Test
"""

import sys
import time
import random
import json
from datetime import datetime
from typing import Dict, List, Any, Optional
from collections import defaultdict

# å¯¼å…¥æ¸¸æˆæ¨¡å—
from game_state import GameState, Player, Avatar, AvatarName
from game_data import GAME_DECK
from multiplayer_manager import create_multiplayer_game
from core_engine import CoreGameEngine, ActionType
from bot_player import get_bot_choice
from enhanced_game_mechanics import enhanced_mechanics

class AIBalanceTest:
    """AIæ™ºèƒ½ç¨‹åº¦å’Œæ¸¸æˆå¹³è¡¡æ€§æµ‹è¯•"""
    
    def __init__(self):
        self.test_results = []
        self.game_statistics = defaultdict(int)
        self.ai_performance = defaultdict(list)
        self.start_time = datetime.now()
        
    def log_test(self, test_name: str, result: str, details: str = ""):
        """è®°å½•æµ‹è¯•ç»“æœ"""
        log_entry = {
            "æ—¶é—´": datetime.now().strftime("%H:%M:%S"),
            "æµ‹è¯•": test_name,
            "ç»“æœ": result,
            "è¯¦æƒ…": details
        }
        self.test_results.append(log_entry)
        print(f"ğŸ§ª {test_name}: {result}")
        if details:
            print(f"   è¯¦æƒ…: {details}")
    
    def test_ai_decision_quality(self, iterations: int = 10):
        """æµ‹è¯•AIå†³ç­–è´¨é‡"""
        print(f"\nğŸ¤– æµ‹è¯•AIå†³ç­–è´¨é‡ ({iterations}æ¬¡è¿­ä»£)...")
        
        decision_scores = []
        
        for i in range(iterations):
            try:
                # åˆ›å»ºä¸åŒçš„æ¸¸æˆæƒ…å†µ
                valid_actions = self._create_test_scenarios()[i % 5]
                
                # è®°å½•AIé€‰æ‹©
                ai_choice = get_bot_choice(valid_actions)
                chosen_action = valid_actions[ai_choice]
                
                # è¯„ä¼°å†³ç­–è´¨é‡
                score = self._evaluate_decision_quality(chosen_action, valid_actions)
                decision_scores.append(score)
                
                self.ai_performance["å†³ç­–è´¨é‡"].append(score)
                
            except Exception as e:
                self.log_test(f"AIå†³ç­–æµ‹è¯•{i+1}", "å¤±è´¥", f"é”™è¯¯: {e}")
                continue
        
        if decision_scores:
            avg_score = sum(decision_scores) / len(decision_scores)
            self.log_test("AIå†³ç­–è´¨é‡", "å®Œæˆ", f"å¹³å‡åˆ†: {avg_score:.2f}/10")
            return avg_score
        else:
            self.log_test("AIå†³ç­–è´¨é‡", "å¤±è´¥", "æ— æœ‰æ•ˆå†³ç­–æ•°æ®")
            return 0
    
    def _create_test_scenarios(self) -> List[Dict]:
        """åˆ›å»ºæµ‹è¯•åœºæ™¯"""
        scenarios = [
            # åœºæ™¯1: ä¼˜åŠ¿å±€é¢
            {
                1: {"action": "play_card", "description": "å‡ºå¼ºåŠ›å¡ç‰Œ", "priority": 9},
                2: {"action": "meditate", "description": "å†¥æƒ³", "priority": 3},
                3: {"action": "pass", "description": "è·³è¿‡", "priority": 1}
            },
            # åœºæ™¯2: åŠ£åŠ¿å±€é¢
            {
                1: {"action": "study", "description": "ç ”ä¹ ", "priority": 7},
                2: {"action": "divine", "description": "å åœ", "priority": 6},
                3: {"action": "pass", "description": "è·³è¿‡", "priority": 2}
            },
            # åœºæ™¯3: å¹³è¡¡å±€é¢
            {
                1: {"action": "play_card", "description": "å‡ºç‰Œ", "priority": 5},
                2: {"action": "move", "description": "ç§»åŠ¨", "priority": 5},
                3: {"action": "meditate", "description": "å†¥æƒ³", "priority": 4}
            },
            # åœºæ™¯4: èµ„æºç´§å¼ 
            {
                1: {"action": "meditate", "description": "å†¥æƒ³æ¢å¤", "priority": 8},
                2: {"action": "study", "description": "ç ”ä¹ ", "priority": 4},
                3: {"action": "pass", "description": "è·³è¿‡", "priority": 3}
            },
            # åœºæ™¯5: ç»ˆå±€é˜¶æ®µ
            {
                1: {"action": "play_card", "description": "å†³èƒœå‡ºç‰Œ", "priority": 10},
                2: {"action": "divine", "description": "å åœ", "priority": 2},
                3: {"action": "pass", "description": "è·³è¿‡", "priority": 1}
            }
        ]
        return scenarios
    
    def _evaluate_decision_quality(self, chosen_action: Dict, all_actions: Dict) -> float:
        """è¯„ä¼°å†³ç­–è´¨é‡"""
        # åŸºäºä¼˜å…ˆçº§è¯„ä¼°å†³ç­–è´¨é‡
        chosen_priority = chosen_action.get("priority", 5)
        max_priority = max(action.get("priority", 5) for action in all_actions.values())
        
        # è®¡ç®—ç›¸å¯¹è´¨é‡åˆ†æ•° (1-10åˆ†)
        if max_priority == 0:
            return 5.0
        
        quality_ratio = chosen_priority / max_priority
        return min(10.0, quality_ratio * 10)
    
    def test_game_balance(self, games: int = 20):
        """æµ‹è¯•æ¸¸æˆå¹³è¡¡æ€§"""
        print(f"\nâš–ï¸ æµ‹è¯•æ¸¸æˆå¹³è¡¡æ€§ ({games}åœºæ¸¸æˆ)...")
        
        win_stats = defaultdict(int)
        game_lengths = []
        
        for game_num in range(games):
            try:
                # åˆ›å»ºæ¸¸æˆ
                players, manager = create_multiplayer_game(2, ["äººç±»ç©å®¶", "AIç©å®¶"])
                game_state = GameState(players=players)
                engine = CoreGameEngine(game_state)
                
                # æ¨¡æ‹Ÿæ¸¸æˆ
                winner, turns = self._simulate_balanced_game(game_state, engine)
                
                if winner:
                    win_stats[winner.name] += 1
                    game_lengths.append(turns)
                    
                    self.log_test(f"æ¸¸æˆ{game_num+1}", "å®Œæˆ", f"èƒœè€…: {winner.name}, å›åˆæ•°: {turns}")
                
            except Exception as e:
                self.log_test(f"æ¸¸æˆ{game_num+1}", "å¤±è´¥", f"é”™è¯¯: {e}")
                continue
        
        # åˆ†æå¹³è¡¡æ€§
        self._analyze_balance(win_stats, game_lengths)
        
        return win_stats, game_lengths
    
    def _simulate_balanced_game(self, game_state: GameState, engine: CoreGameEngine, max_turns: int = 50):
        """æ¨¡æ‹Ÿå¹³è¡¡æ¸¸æˆ"""
        turns = 0
        
        # å‘ç‰Œ
        deck = GAME_DECK.copy()
        random.shuffle(deck)
        
        for player in game_state.players:
            for _ in range(5):
                if deck:
                    player.hand.append(deck.pop())
        
        # æ¸¸æˆå¾ªç¯
        while turns < max_turns:
            current_player = game_state.get_current_player()
            
            # æ¨¡æ‹Ÿç©å®¶è¡ŒåŠ¨
            if "AI" in current_player.name:
                # AIç©å®¶å†³ç­–
                valid_actions = self._get_valid_actions(current_player, game_state)
                if valid_actions:
                    choice = get_bot_choice(valid_actions)
                    self._execute_action(current_player, valid_actions[choice], game_state)
            else:
                # äººç±»ç©å®¶æ¨¡æ‹Ÿï¼ˆéšæœºå†³ç­–ï¼‰
                self._simulate_human_action(current_player, game_state)
            
            # æ£€æŸ¥èƒœåˆ©æ¡ä»¶
            winner = self._check_simple_victory(game_state)
            if winner:
                return winner, turns
            
            # ä¸‹ä¸€å›åˆ
            game_state.current_player_index = (game_state.current_player_index + 1) % len(game_state.players)
            turns += 1
        
        # è¶…æ—¶åˆ¤å®š
        return self._determine_winner_by_score(game_state), turns
    
    def _get_valid_actions(self, player: Player, game_state: GameState) -> Dict:
        """è·å–æœ‰æ•ˆè¡ŒåŠ¨"""
        actions = {}
        action_id = 1
        
        # å‡ºç‰Œ
        if player.hand and player.qi >= 1:
            actions[action_id] = {"action": "play_card", "description": "å‡ºç‰Œ"}
            action_id += 1
        
        # å†¥æƒ³
        if player.qi < 10:
            actions[action_id] = {"action": "meditate", "description": "å†¥æƒ³"}
            action_id += 1
        
        # ç ”ä¹ 
        if player.qi >= 2:
            actions[action_id] = {"action": "study", "description": "ç ”ä¹ "}
            action_id += 1
        
        # è·³è¿‡
        actions[action_id] = {"action": "pass", "description": "è·³è¿‡"}
        
        return actions
    
    def _execute_action(self, player: Player, action: Dict, game_state: GameState):
        """æ‰§è¡Œè¡ŒåŠ¨"""
        action_type = action["action"]
        
        if action_type == "play_card" and player.hand:
            # å‡ºç‰Œ
            card = player.hand.pop(0)
            player.qi = max(0, player.qi - 1)
            player.dao_xing += 1
            
        elif action_type == "meditate":
            # å†¥æƒ³
            player.qi = min(10, player.qi + 2)
            
        elif action_type == "study":
            # ç ”ä¹ 
            player.qi = max(0, player.qi - 2)
            player.dao_xing += 2
    
    def _simulate_human_action(self, player: Player, game_state: GameState):
        """æ¨¡æ‹Ÿäººç±»ç©å®¶è¡ŒåŠ¨"""
        valid_actions = self._get_valid_actions(player, game_state)
        if valid_actions:
            choice = random.choice(list(valid_actions.keys()))
            self._execute_action(player, valid_actions[choice], game_state)
    
    def _check_simple_victory(self, game_state: GameState) -> Optional[Player]:
        """ç®€å•èƒœåˆ©æ¡ä»¶æ£€æŸ¥"""
        for player in game_state.players:
            if player.dao_xing >= 20:  # é“è¡Œè¾¾åˆ°20è·èƒœ
                return player
        return None
    
    def _determine_winner_by_score(self, game_state: GameState) -> Optional[Player]:
        """æ ¹æ®åˆ†æ•°ç¡®å®šèƒœè€…"""
        if not game_state.players:
            return None
        
        return max(game_state.players, key=lambda p: p.dao_xing + p.qi)
    
    def _analyze_balance(self, win_stats: Dict, game_lengths: List[int]):
        """åˆ†ææ¸¸æˆå¹³è¡¡æ€§"""
        total_games = sum(win_stats.values())
        
        if total_games == 0:
            self.log_test("å¹³è¡¡æ€§åˆ†æ", "å¤±è´¥", "æ— æœ‰æ•ˆæ¸¸æˆæ•°æ®")
            return
        
        # èƒœç‡åˆ†æ
        for player, wins in win_stats.items():
            win_rate = (wins / total_games) * 100
            self.log_test(f"{player}èƒœç‡", "ç»Ÿè®¡", f"{win_rate:.1f}% ({wins}/{total_games})")
        
        # æ¸¸æˆé•¿åº¦åˆ†æ
        if game_lengths:
            avg_length = sum(game_lengths) / len(game_lengths)
            min_length = min(game_lengths)
            max_length = max(game_lengths)
            
            self.log_test("æ¸¸æˆé•¿åº¦", "ç»Ÿè®¡", f"å¹³å‡{avg_length:.1f}å›åˆ (èŒƒå›´: {min_length}-{max_length})")
        
        # å¹³è¡¡æ€§è¯„ä¼°
        ai_wins = win_stats.get("AIç©å®¶", 0)
        human_wins = win_stats.get("äººç±»ç©å®¶", 0)
        
        if total_games > 0:
            ai_win_rate = (ai_wins / total_games) * 100
            balance_score = 100 - abs(50 - ai_win_rate) * 2  # è¶Šæ¥è¿‘50%è¶Šå¹³è¡¡
            
            if balance_score >= 80:
                balance_level = "ä¼˜ç§€"
            elif balance_score >= 60:
                balance_level = "è‰¯å¥½"
            else:
                balance_level = "éœ€æ”¹è¿›"
            
            self.log_test("å¹³è¡¡æ€§è¯„ä¼°", balance_level, f"å¹³è¡¡åˆ†æ•°: {balance_score:.1f}/100")
    
    def test_ai_adaptability(self):
        """æµ‹è¯•AIé€‚åº”æ€§"""
        print("\nğŸ”„ æµ‹è¯•AIé€‚åº”æ€§...")
        
        adaptability_scores = []
        
        # æµ‹è¯•ä¸åŒéš¾åº¦åœºæ™¯
        scenarios = [
            ("ç®€å•åœºæ™¯", {"complexity": 1, "pressure": 1}),
            ("ä¸­ç­‰åœºæ™¯", {"complexity": 5, "pressure": 3}),
            ("å›°éš¾åœºæ™¯", {"complexity": 8, "pressure": 7}),
            ("æé™åœºæ™¯", {"complexity": 10, "pressure": 10})
        ]
        
        for scenario_name, params in scenarios:
            try:
                score = self._test_scenario_adaptability(scenario_name, params)
                adaptability_scores.append(score)
                self.log_test(f"é€‚åº”æ€§-{scenario_name}", "å®Œæˆ", f"å¾—åˆ†: {score:.1f}/10")
                
            except Exception as e:
                self.log_test(f"é€‚åº”æ€§-{scenario_name}", "å¤±è´¥", f"é”™è¯¯: {e}")
        
        if adaptability_scores:
            avg_adaptability = sum(adaptability_scores) / len(adaptability_scores)
            self.log_test("AIé€‚åº”æ€§", "è¯„ä¼°", f"ç»¼åˆå¾—åˆ†: {avg_adaptability:.1f}/10")
            return avg_adaptability
        
        return 0
    
    def _test_scenario_adaptability(self, scenario_name: str, params: Dict) -> float:
        """æµ‹è¯•åœºæ™¯é€‚åº”æ€§"""
        complexity = params["complexity"]
        pressure = params["pressure"]
        
        # åˆ›å»ºå¤æ‚åº¦ç›¸åº”çš„è¡ŒåŠ¨é€‰é¡¹
        num_actions = min(2 + complexity, 8)
        valid_actions = {}
        
        for i in range(num_actions):
            priority = random.randint(1, 10)
            # åœ¨é«˜å‹åŠ›æƒ…å†µä¸‹ï¼Œé™ä½æŸäº›é€‰é¡¹çš„ä¼˜å…ˆçº§
            if pressure > 5 and random.random() < 0.3:
                priority = max(1, priority - pressure)
            
            valid_actions[i + 1] = {
                "action": f"action_{i+1}",
                "description": f"è¡ŒåŠ¨{i+1}",
                "priority": priority
            }
        
        # æµ‹è¯•AIåœ¨æ­¤åœºæ™¯ä¸‹çš„è¡¨ç°
        correct_decisions = 0
        total_decisions = 10
        
        for _ in range(total_decisions):
            ai_choice = get_bot_choice(valid_actions)
            chosen_action = valid_actions[ai_choice]
            
            # è¯„ä¼°å†³ç­–æ˜¯å¦åˆç†
            if self._is_reasonable_decision(chosen_action, valid_actions, complexity, pressure):
                correct_decisions += 1
        
        return (correct_decisions / total_decisions) * 10
    
    def _is_reasonable_decision(self, chosen_action: Dict, all_actions: Dict, complexity: int, pressure: int) -> bool:
        """åˆ¤æ–­å†³ç­–æ˜¯å¦åˆç†"""
        chosen_priority = chosen_action.get("priority", 5)
        max_priority = max(action.get("priority", 5) for action in all_actions.values())
        
        # åœ¨é«˜å¤æ‚åº¦å’Œé«˜å‹åŠ›ä¸‹ï¼Œè¦æ±‚æ›´é«˜çš„å†³ç­–è´¨é‡
        threshold = 0.7 if complexity > 7 or pressure > 7 else 0.5
        
        return (chosen_priority / max_priority) >= threshold if max_priority > 0 else True
    
    def generate_ai_balance_report(self):
        """ç”ŸæˆAIå’Œå¹³è¡¡æ€§æµ‹è¯•æŠ¥å‘Š"""
        print("\nğŸ“Š ç”ŸæˆAIå’Œå¹³è¡¡æ€§æµ‹è¯•æŠ¥å‘Š...")
        
        end_time = datetime.now()
        duration = (end_time - self.start_time).total_seconds()
        
        # ç»Ÿè®¡æµ‹è¯•ç»“æœ
        total_tests = len(self.test_results)
        successful_tests = len([test for test in self.test_results if test["ç»“æœ"] not in ["å¤±è´¥", "é”™è¯¯"]])
        success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0
        
        # è®¡ç®—AIæ€§èƒ½æŒ‡æ ‡
        ai_metrics = {}
        for metric, scores in self.ai_performance.items():
            if scores:
                ai_metrics[metric] = {
                    "å¹³å‡åˆ†": sum(scores) / len(scores),
                    "æœ€é«˜åˆ†": max(scores),
                    "æœ€ä½åˆ†": min(scores),
                    "æ ·æœ¬æ•°": len(scores)
                }
        
        report = {
            "æµ‹è¯•æ—¶é—´": self.start_time.strftime("%Y-%m-%d %H:%M:%S"),
            "æµ‹è¯•æ—¶é•¿": f"{duration:.2f}ç§’",
            "æ€»æµ‹è¯•æ•°": total_tests,
            "æˆåŠŸæµ‹è¯•æ•°": successful_tests,
            "æˆåŠŸç‡": f"{success_rate:.1f}%",
            "AIæ€§èƒ½æŒ‡æ ‡": ai_metrics,
            "è¯¦ç»†æµ‹è¯•æ—¥å¿—": self.test_results,
            "ç»¼åˆè¯„ä¼°": {
                "AIæ™ºèƒ½ç¨‹åº¦": "ä¼˜ç§€" if success_rate >= 90 else "è‰¯å¥½" if success_rate >= 70 else "éœ€æ”¹è¿›",
                "æ¸¸æˆå¹³è¡¡æ€§": "å·²æµ‹è¯•" if successful_tests >= 10 else "æ•°æ®ä¸è¶³",
                "ç³»ç»Ÿç¨³å®šæ€§": "ç¨³å®š" if success_rate >= 85 else "ä¸€èˆ¬"
            }
        }
        
        # ä¿å­˜æŠ¥å‘Š
        with open("ai_balance_test_report.json", "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“‹ AIå’Œå¹³è¡¡æ€§æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: ai_balance_test_report.json")
        print(f"â­ æ€»ä½“è¯„åˆ†: {success_rate:.1f}%")
        
        return report
    
    def run_full_ai_balance_test(self):
        """è¿è¡Œå®Œæ•´çš„AIå’Œå¹³è¡¡æ€§æµ‹è¯•"""
        print("=" * 60)
        print("ğŸ¤– å¤©æœºå˜æ¸¸æˆ - AIæ™ºèƒ½ç¨‹åº¦å’Œæ¸¸æˆå¹³è¡¡æ€§æµ‹è¯•")
        print("=" * 60)
        
        # 1. AIå†³ç­–è´¨é‡æµ‹è¯•
        self.test_ai_decision_quality(20)
        
        # 2. æ¸¸æˆå¹³è¡¡æ€§æµ‹è¯•
        self.test_game_balance(15)
        
        # 3. AIé€‚åº”æ€§æµ‹è¯•
        self.test_ai_adaptability()
        
        # 4. ç”ŸæˆæŠ¥å‘Š
        report = self.generate_ai_balance_report()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ AIæ™ºèƒ½ç¨‹åº¦å’Œæ¸¸æˆå¹³è¡¡æ€§æµ‹è¯•å®Œæˆ!")
        print("=" * 60)
        
        return report

def main():
    """ä¸»å‡½æ•°"""
    tester = AIBalanceTest()
    return tester.run_full_ai_balance_test()

if __name__ == "__main__":
    main()